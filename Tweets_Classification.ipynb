{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим необходимые нам библиотеки и посмотрим на данные. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\dkiro\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\dkiro\\Desktop\\проект\\toxic_comments.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на соотношение токсичных и нормальных комментариев в датасете. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(df.toxic.value_counts(normalize = True) * 100).plot(kind = 'bar',\n",
    "                                                     title = 'Normal to toxic relation');\n",
    "plt.ylabel('Percentage, %', fontsize = 'large');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На диаграмме можно заметить, что токсичных комментариев в разы меньше, чем обычных. С точки зрения моделирования это не очень хорошо, поэтому будем учитывать этот момент подборе оптимальных моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очистим столбец с текстом от всего лишнего. Уберем все символы, кроме английских и затем лемматизируем их, убрав стоп-слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    text = (re.sub(r'[^a-zA-Z]', ' ', text)).split(' ')\n",
    "    text = ' '.join([word for word in text if word not in stop_words])\n",
    "    text = ' '.join([m.lemmatize(word) for word in text.split()])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим функцию clear_text к столбцу *text*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemmed_text'] = df['text'].apply(clear_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemmed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>Explanation Why edits made username Hardcore M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>D aww He match background colour I seemingly s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>Hey man I really trying edit war It guy consta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>More I make real suggestion improvement I wond...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>You sir hero Any chance remember page</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Congratulations well use tool well talk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "      <td>Your vandalism Matt Shirvington article revert...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "5  \"\\n\\nCongratulations from me as well, use the ...      0   \n",
       "6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1   \n",
       "7  Your vandalism to the Matt Shirvington article...      0   \n",
       "\n",
       "                                         lemmed_text  \n",
       "0  Explanation Why edits made username Hardcore M...  \n",
       "1  D aww He match background colour I seemingly s...  \n",
       "2  Hey man I really trying edit war It guy consta...  \n",
       "3  More I make real suggestion improvement I wond...  \n",
       "4              You sir hero Any chance remember page  \n",
       "5            Congratulations well use tool well talk  \n",
       "6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK  \n",
       "7  Your vandalism Matt Shirvington article revert...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val_test = train_test_split(df, test_size = 0.4,\n",
    "                                         random_state = 123)\n",
    "\n",
    "df_val, df_test = train_test_split(df_val_test, test_size = 0.5,\n",
    "                                   random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.lemmed_text.values # обучающая выборка \n",
    "y_train = df_train.toxic.values\n",
    "\n",
    "X_val = df_val.lemmed_text.values # валидационная выборка\n",
    "y_val = df_val.toxic.values\n",
    "\n",
    "X_test = df_test.lemmed_text.values  # тестовая выборка \n",
    "y_test = df_test.toxic.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переведем тесты из твиттера в векторный формат с помощью TF-IDF меры. В этой модели вес некоторого слова пропорционален частоте употребления этого слова в документе и обратно пропорционален частоте употребления слова во всех документах коллекции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer(stop_words = stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tf_idf = tf_idf.fit_transform(X_train)\n",
    "val_tf_idf = tf_idf.transform(X_val)\n",
    "test_tf_idf = tf_idf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерность тренировочного набора данных: (95742, 121254)\n",
      "Размерность валидационного набора данных: (31914, 121254)\n",
      "Размерность тестового набора данных: (31915, 121254)\n"
     ]
    }
   ],
   "source": [
    "print('Размерность тренировочного набора данных:', train_tf_idf.shape)\n",
    "print('Размерность валидационного набора данных:', val_tf_idf.shape)\n",
    "print('Размерность тестового набора данных:', test_tf_idf.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель логистической регрессии на тренировочном корпусе и проверим качество модели на валидационной выборке. Модель с наибольшим F1_val будет считаться наилучшей. Зафиксируем max_iter = 300 и будем менять параметр C, отвечающий за регуляризацию регрессии. Поскольку классы у нас несбалансированные, поставим параметр class_weight='balanced'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " С = 1.0 | F1_val = 0.7369\n",
      " С = 1.44 | F1_val = 0.7443\n",
      " С = 1.89 | F1_val = 0.7466\n",
      " С = 2.33 | F1_val = 0.7483\n",
      " С = 2.78 | F1_val = 0.7495\n",
      " С = 3.22 | F1_val = 0.7512\n",
      " С = 3.67 | F1_val = 0.7528\n",
      " С = 4.11 | F1_val = 0.7522\n",
      " С = 4.56 | F1_val = 0.7513\n",
      " С = 5.0 | F1_val = 0.7516\n",
      "Лучшая модель логистической регрессии: LogisticRegression(C=3.6666666666666665, class_weight='balanced', max_iter=300,\n",
      "                   random_state=123)\n"
     ]
    }
   ],
   "source": [
    "best_model_lg = None\n",
    "best_f1 = 0\n",
    "\n",
    "for c in np.linspace(1, 5, 10):\n",
    "    model = LogisticRegression(max_iter=300,\n",
    "                               C = c,\n",
    "                               random_state=123,\n",
    "                               class_weight='balanced')\n",
    "    \n",
    "    model.fit(train_tf_idf, y_train)\n",
    "    predictions = model.predict(val_tf_idf)\n",
    "    val_f1_score = f1_score(y_val, predictions)\n",
    "    \n",
    "    if val_f1_score > best_f1:\n",
    "        best_f1 = val_f1_score\n",
    "        best_model_lg = model\n",
    "        \n",
    "    print(f' С = {round(c, 2)} | F1_val = {round(val_f1_score, 4)}')\n",
    "    \n",
    "print('Лучшая модель логистической регрессии:', best_model_lg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно заметить, что с ростом параметра C, значение метрики F1 также растет какое-то время. Однако после значения С=3.67, F1 на валидации падает. Соответственно, при значении C=3.67 F1 на валидации наибольший, это и будет оптимальная модель логистической регрессии.\n",
    "\n",
    "Теперь аналогичным образом проверим работу алгоритма дерева решений на наших данных, только в этот раз будем менять глубину деревa и также, как и с логистичекой регрессией, поставим class_weight='balanced'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " max_depth = 6 | F1_val = 0.4794\n",
      " max_depth = 9 | F1_val = 0.5409\n",
      " max_depth = 12 | F1_val = 0.5819\n",
      " max_depth = 15 | F1_val = 0.6092\n",
      " max_depth = 18 | F1_val = 0.5965\n",
      " max_depth = 21 | F1_val = 0.6134\n",
      " max_depth = 24 | F1_val = 0.6258\n",
      "Лучшая модель дерева решений: DecisionTreeClassifier(class_weight='balanced', max_depth=24, random_state=123)\n"
     ]
    }
   ],
   "source": [
    "best_model_dtr = None\n",
    "best_f1 = 0\n",
    "\n",
    "for depth in range(6, 26, 3):\n",
    "    model = DecisionTreeClassifier(max_depth = depth,\n",
    "                                   random_state=123,\n",
    "                                   class_weight='balanced')\n",
    "    \n",
    "    model.fit(train_tf_idf, y_train)\n",
    "    predictions = model.predict(val_tf_idf)\n",
    "    val_f1_score = f1_score(y_val, predictions)\n",
    "    \n",
    "    if val_f1_score > best_f1:\n",
    "        best_f1 = val_f1_score\n",
    "        best_model_dtr = model\n",
    "    print(f' max_depth = {depth} | F1_val = {round(val_f1_score, 4)}')\n",
    "    \n",
    "print('Лучшая модель дерева решений:',best_model_dtr )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C увеличением максимальной глубины дерева F1 также растет. Однако значение метрики меньше, чем для логистической регрессии, соответственно, модель предсказывает классы твиттов хуже. Кроме того модель дольше обучается.\n",
    "\n",
    "Проверим наконец модель градиентного бустинга. В качестве изменяющегося параметра возьмем learning_rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " learting_rate = 0.01 | F1_val = 0.6377\n",
      " learting_rate = 0.1 | F1_val = 0.723\n",
      " learting_rate = 0.5 | F1_val = 0.745\n",
      " learting_rate = 0.9 | F1_val = 0.7195\n",
      "Лучшая модель градиентного бустинга: LGBMClassifier(class_weight='balanced', learning_rate=0.5, max_depth=13,\n",
      "               random_state=123)\n"
     ]
    }
   ],
   "source": [
    "learning_rate_gb = [\n",
    "    0.01, 0.1,\n",
    "    0.5, 0.9\n",
    "]\n",
    "\n",
    "best_model_gb = None\n",
    "best_f1 = 0\n",
    "\n",
    "for rate in learning_rate_gb:\n",
    "    model = lgb.LGBMClassifier(random_state = 123,\n",
    "                               max_depth = 13,\n",
    "                               learning_rate = rate,\n",
    "                               class_weight = 'balanced')\n",
    "    \n",
    "    model.fit(train_tf_idf, y_train)\n",
    "    predictions = model.predict(val_tf_idf)\n",
    "    val_f1_score = f1_score(y_val, predictions)\n",
    "    \n",
    "    if val_f1_score > best_f1:\n",
    "        best_f1 = val_f1_score\n",
    "        best_model_gb = model\n",
    "    print(f' learting_rate = {rate} | F1_val = {round(val_f1_score, 4)}')\n",
    "    \n",
    "print('Лучшая модель градиентного бустинга:', best_model_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C ростом learning_rate значение метрики F1 также растет какое-то время. Однако после rate = 0.5, F1 на валидации падает. Соответственно, при значении rate = 0.5 F1 на валидации наибольший, это и будет оптимальная модель градиентного бустинга.\n",
    "\n",
    "Сравним качество всех трех моделей с лучшими параметрами на тесте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_test_lg: 0.763\n",
      "F1_test_dtr: 0.609\n",
      "F1_test_gb: 0.748\n"
     ]
    }
   ],
   "source": [
    "predict_lg = best_model_lg.predict(test_tf_idf)\n",
    "test_f1_lg = f1_score(y_test, predict_lg)\n",
    "\n",
    "\n",
    "predict_dtr = best_model_dtr.predict(test_tf_idf)\n",
    "test_f1_dtr = f1_score(y_test, predict_dtr)\n",
    "\n",
    "\n",
    "predict_gb = best_model_gb.predict(test_tf_idf)\n",
    "test_f1_gb = f1_score(y_test, predict_gb)\n",
    "\n",
    "\n",
    "print('F1_test_lg:', round(test_f1_lg, 3))\n",
    "print('F1_test_dtr:', round(test_f1_dtr, 3))\n",
    "print('F1_test_gb:', round(test_f1_gb, 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы очистили твитты от лишних символов и привели каждое слово твитта к исходной форме - лемме. Затем было проверено три модели с различными гипер параметрами: логистическая регрессия, дерево решений и градиентный бустинг. \n",
    "\n",
    "Лучшей моделью как по скорости, так и по качеству модели на тестовой выборке стала логистическая регрессия с параметрами max_iter=300 и С = 3.67. F1 на тестовой выборке составил 0.763, что больше 0.75. Значит, с поставленной задачей мы справились."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
